{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reddit_flair_detector.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cscZR-8v3PCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data_final=pd.read_csv(\"/content/drive/My Drive/data_final(reddit)\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YeITEiJ8Kcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WodTYqrT8NoZ",
        "colab_type": "code",
        "outputId": "09074aba-20a6-419e-e1df-1554582396a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>author</th>\n",
              "      <th>authors</th>\n",
              "      <th>body</th>\n",
              "      <th>comment</th>\n",
              "      <th>comms_num</th>\n",
              "      <th>created</th>\n",
              "      <th>flair</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dhavalcoholic</td>\n",
              "      <td>ICICIPruLifeIns</td>\n",
              "      <td>reposting lack activity r askindiahello last y...</td>\n",
              "      <td>dear policy holder dhavalcoholic request help ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.386254e+09</td>\n",
              "      <td>AskIndia</td>\n",
              "      <td>1s57oi</td>\n",
              "      <td>1</td>\n",
              "      <td>need feedback insurance policy took xpost aski...</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/1s57oi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>amitkumarthakur</td>\n",
              "      <td>RAD-Business RAD-Business None barcam10 _snor...</td>\n",
              "      <td>24hrs local police station register case dont ...</td>\n",
              "      <td>calm downgo sp office town file grievance imme...</td>\n",
              "      <td>24</td>\n",
              "      <td>1.554080e+09</td>\n",
              "      <td>AskIndia</td>\n",
              "      <td>b7pvwt</td>\n",
              "      <td>94</td>\n",
              "      <td>somebody want kill full family</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/b7pvwt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>FrustratedOCIHopeful</td>\n",
              "      <td>plshelpthedog ayyylmaaaoo Proper_Boysenberry ...</td>\n",
              "      <td>hello askindia first time poster long time lur...</td>\n",
              "      <td>honestly supervisor behaved exactly government...</td>\n",
              "      <td>27</td>\n",
              "      <td>1.555361e+09</td>\n",
              "      <td>AskIndia</td>\n",
              "      <td>bdfid1</td>\n",
              "      <td>10</td>\n",
              "      <td>ambassador india takes back newly issued oci c...</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/bdfid1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>aloo_vs_bhaloo</td>\n",
              "      <td>vcdarklord tilismilis aloo_vs_bhaloo dogaa fo...</td>\n",
              "      <td>r tooafraidtoask india edition</td>\n",
              "      <td>modi control sex desires jerk someone else pro...</td>\n",
              "      <td>22</td>\n",
              "      <td>1.566529e+09</td>\n",
              "      <td>AskIndia</td>\n",
              "      <td>cu1xn4</td>\n",
              "      <td>18</td>\n",
              "      <td>randians afraid ask</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/cu1xn4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>multubunu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hello submitted r raskindia week ago got answe...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1.361085e+09</td>\n",
              "      <td>AskIndia</td>\n",
              "      <td>18ntue</td>\n",
              "      <td>0</td>\n",
              "      <td>askindia cingari cengar tzengar</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/18ntue...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3555</th>\n",
              "      <td>2425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AlternativeDrop6</td>\n",
              "      <td>jnik27promiscuous_bhismaKemosahbeolololopololo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bc dunia khtm hogi is saal lagta haiThe resear...</td>\n",
              "      <td>35</td>\n",
              "      <td>1.586954e+09</td>\n",
              "      <td>Coronavirus</td>\n",
              "      <td>g1l2lv</td>\n",
              "      <td>138</td>\n",
              "      <td>Coronavirus Mutation Found in India “Raises Al...</td>\n",
              "      <td>https://weather.com/en-IN/india/coronavirus/ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3556</th>\n",
              "      <td>2426</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dumma1729</td>\n",
              "      <td>qwertyzxcvbnmpoiuy-The-Bat-budbukAnxiousBlocka...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Because as the great George Carlin once said -...</td>\n",
              "      <td>26</td>\n",
              "      <td>1.587671e+09</td>\n",
              "      <td>Coronavirus</td>\n",
              "      <td>g6l7hl</td>\n",
              "      <td>85</td>\n",
              "      <td>As India’s Poor Demand Relief, Why Are Middle ...</td>\n",
              "      <td>https://www.newsclick.in/India-Poor-Demand-Rel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3557</th>\n",
              "      <td>2427</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GL4389</td>\n",
              "      <td>BhayanakMuutabd_min_ibadillahKemosahbeTimbaktu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&gt; None of them have shown any symptoms of Covi...</td>\n",
              "      <td>18</td>\n",
              "      <td>1.587410e+09</td>\n",
              "      <td>Coronavirus</td>\n",
              "      <td>g4qvfx</td>\n",
              "      <td>153</td>\n",
              "      <td>Out of money, 6 foreigners make home inside ca...</td>\n",
              "      <td>https://www.hindustantimes.com/india-news/out-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3558</th>\n",
              "      <td>2428</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>n1ght_w1ng08</td>\n",
              "      <td>vindicators_riseKissMyBBQMAA_KI_CHUDIYAmrfreez...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The other day I saw a video where business was...</td>\n",
              "      <td>36</td>\n",
              "      <td>1.586001e+09</td>\n",
              "      <td>Coronavirus</td>\n",
              "      <td>fumux8</td>\n",
              "      <td>573</td>\n",
              "      <td>Doctors say India must prepare for an 'onslaug...</td>\n",
              "      <td>https://edition.cnn.com/2020/04/03/asia/india-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3559</th>\n",
              "      <td>2429</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hipporama</td>\n",
              "      <td>sadar_pranamtigergoatguavabudbukNone-DrugsAndH...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I am sure ( some %age) police would be  exploi...</td>\n",
              "      <td>39</td>\n",
              "      <td>1.585396e+09</td>\n",
              "      <td>Coronavirus</td>\n",
              "      <td>fqcq8y</td>\n",
              "      <td>890</td>\n",
              "      <td>Bihar: Three police constables arrested after ...</td>\n",
              "      <td>https://twitter.com/PTI_News/status/1243446708...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3560 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                                url\n",
              "0              0  ...  https://www.reddit.com/r/india/comments/1s57oi...\n",
              "1              1  ...  https://www.reddit.com/r/india/comments/b7pvwt...\n",
              "2              2  ...  https://www.reddit.com/r/india/comments/bdfid1...\n",
              "3              3  ...  https://www.reddit.com/r/india/comments/cu1xn4...\n",
              "4              4  ...  https://www.reddit.com/r/india/comments/18ntue...\n",
              "...          ...  ...                                                ...\n",
              "3555        2425  ...  https://weather.com/en-IN/india/coronavirus/ne...\n",
              "3556        2426  ...  https://www.newsclick.in/India-Poor-Demand-Rel...\n",
              "3557        2427  ...  https://www.hindustantimes.com/india-news/out-...\n",
              "3558        2428  ...  https://edition.cnn.com/2020/04/03/asia/india-...\n",
              "3559        2429  ...  https://twitter.com/PTI_News/status/1243446708...\n",
              "\n",
              "[3560 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzjMHb07-VrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_final=data_final.fillna(\"True\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTEa5xR_iL-k",
        "colab_type": "text"
      },
      "source": [
        "**Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFyaapKUtPQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.externals import joblib\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2ADQqceijIH",
        "colab_type": "text"
      },
      "source": [
        "Defining Flairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2nDhSKWo8NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \n",
        "          \"Scheduled\", \"Photography\", \"Science/Technology\",\n",
        "          \"Politics\", \"Business/Finance\", \"Policy/Economy\",\n",
        "          \"Sports\", \"Food\", \"AMA\",\"Coronavirus\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_KOb06SiobN",
        "colab_type": "text"
      },
      "source": [
        "**Making funcitons for different ML algorithms to be used**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ2-6FfKi5Jn",
        "colab_type": "text"
      },
      "source": [
        "**Logistic_Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfLLEeC9uUKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logisticreg(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "  logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', LogisticRegression(n_jobs=1, C=1e3)),\n",
        "                 ])\n",
        "  logreg.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = logreg.predict(X_test)\n",
        "\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qXSoJ9ei-m-",
        "colab_type": "text"
      },
      "source": [
        "**Naive_Bayes_Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKpsVGVXuV04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nb_classifier(X_train, X_test, y_train, y_test):\n",
        "  nb = Pipeline([('vect', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('clf', MultinomialNB()),\n",
        "                ])\n",
        "  nb.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = nb.predict(X_test)\n",
        "\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ChN85RVjEHo",
        "colab_type": "text"
      },
      "source": [
        "**Linear_SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rORAa0OuXmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def linear_svm(X_train, X_test, y_train, y_test):\n",
        "  sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "                 ])\n",
        "  sgd.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = sgd.predict(X_test)\n",
        "\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrs95qrLjHd-",
        "colab_type": "text"
      },
      "source": [
        "**Random_Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSbzxV3xuZIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomforest(X_train, X_test, y_train, y_test):\n",
        "  ranfor = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', RandomForestClassifier(n_estimators = 1000, random_state = 42)),\n",
        "                 ])\n",
        "  ranfor.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = ranfor.predict(X_test)\n",
        "\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2OyvbW5jKnx",
        "colab_type": "text"
      },
      "source": [
        "**MLP_classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkHgkeFFubuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlpclassifier(X_train, X_test, y_train, y_test):  \n",
        "  mlp = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', MLPClassifier(hidden_layer_sizes=(30,30,30))),\n",
        "                 ])\n",
        "  mlp.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = mlp.predict(X_test)\n",
        "\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=flairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2pWBW-YjRfP",
        "colab_type": "text"
      },
      "source": [
        "**This is the function which will take as input (features and labels) split them into training and testing (20%) and then call different machine learning algorithms (passing training and validation set as arguments)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VkwxCWDudXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test(X,y):\n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "   \n",
        "    print(\"Results of Naive Bayes Classifier\")\n",
        "    nb_classifier(X_train, X_test, y_train, y_test)\n",
        "    print('----------------------------------------------------------------------------------')\n",
        "    print(\"Results of Linear Support Vector Machine\")\n",
        "    linear_svm(X_train, X_test, y_train, y_test)\n",
        "    print('----------------------------------------------------------------------------------')\n",
        "    print(\"Results of Logistic Regression\")\n",
        "    logisticreg(X_train, X_test, y_train, y_test)\n",
        "    print('----------------------------------------------------------------------------------')\n",
        "    print(\"Results of Random Forest\")\n",
        "    randomforest(X_train, X_test, y_train, y_test)\n",
        "    print('----------------------------------------------------------------------------------')\n",
        "    print(\"Results of MLP Classifier\")\n",
        "    mlpclassifier(X_train, X_test, y_train, y_test)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA4yI4oOkIOC",
        "colab_type": "text"
      },
      "source": [
        "**Trying standalone imputs and their combination as features**\n",
        "Training on comments and title alone gave significantly good models , whereas body was not present in some posts so it didn't performed well as a feature .\n",
        "\n",
        "Combining these is a good idea to train model on more information per post ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6i87yX0uivu",
        "colab_type": "code",
        "outputId": "bdd62496-04ee-44cc-91da-8879763e40ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "flair = data_final.flair\n",
        "\n",
        "\n",
        "c = data_final.comment\n",
        "t = data_final.title\n",
        "b = data_final.body\n",
        "u = data_final.url\n",
        "\n",
        "data_final['combined_features']=c+t+b+u\n",
        "\n",
        "combined_features=data_final.combined_features\n",
        "\n",
        "\n",
        "print(\"Flair Detection using Title as Feature\")\n",
        "train_test(t,flair)\n",
        "print(\"Trying with different Feature -----------------------\")\n",
        "print(\"Flair Detection using Body as Feature\")\n",
        "train_test(b,flair)\n",
        "print(\"Trying with different Feature -----------------------\")\n",
        "print(\"Flair Detection using URL as Feature\")\n",
        "train_test(u,flair)\n",
        "print(\"Trying with different Feature -----------------------\")\n",
        "print(\"Flair Detection using Comments as Feature\")\n",
        "train_test(c,flair)\n",
        "print(\"Trying with different Feature -----------------------\")\n",
        "\n",
        "print(\"Flair Detection using Combined Features\")\n",
        "train_test(combined_features,flair)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flair Detection using Title as Feature\n",
            "Results of Naive Bayes Classifier\n",
            "accuracy 0.523876404494382\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       1.00      0.04      0.08        24\n",
            "     Non-Political       0.34      0.81      0.48        59\n",
            "     [R]eddiquette       0.45      0.31      0.37        68\n",
            "         Scheduled       0.79      0.21      0.33        52\n",
            "       Photography       0.00      0.00      0.00        21\n",
            "Science/Technology       0.44      0.54      0.49        68\n",
            "          Politics       0.81      0.75      0.78        68\n",
            "  Business/Finance       0.32      0.60      0.41        57\n",
            "    Policy/Economy       0.42      0.44      0.43        68\n",
            "            Sports       0.86      0.79      0.82        91\n",
            "              Food       0.57      0.42      0.48        69\n",
            "               AMA       0.80      0.62      0.70        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.52       712\n",
            "         macro avg       0.52      0.43      0.41       712\n",
            "      weighted avg       0.58      0.52      0.51       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Linear Support Vector Machine\n",
            "accuracy 0.5912921348314607\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.57      0.50      0.53        24\n",
            "     Non-Political       0.49      0.66      0.56        59\n",
            "     [R]eddiquette       0.53      0.46      0.49        68\n",
            "         Scheduled       0.49      0.37      0.42        52\n",
            "       Photography       0.76      0.76      0.76        21\n",
            "Science/Technology       0.49      0.53      0.51        68\n",
            "          Politics       0.71      0.82      0.76        68\n",
            "  Business/Finance       0.42      0.49      0.45        57\n",
            "    Policy/Economy       0.46      0.41      0.43        68\n",
            "            Sports       0.89      0.85      0.87        91\n",
            "              Food       0.56      0.42      0.48        69\n",
            "               AMA       0.68      0.79      0.73        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.59       712\n",
            "         macro avg       0.54      0.54      0.54       712\n",
            "      weighted avg       0.59      0.59      0.59       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Logistic Regression\n",
            "accuracy 0.5674157303370787\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.80      0.50      0.62        24\n",
            "     Non-Political       0.49      0.61      0.55        59\n",
            "     [R]eddiquette       0.43      0.38      0.40        68\n",
            "         Scheduled       0.35      0.33      0.34        52\n",
            "       Photography       0.93      0.62      0.74        21\n",
            "Science/Technology       0.50      0.56      0.53        68\n",
            "          Politics       0.74      0.75      0.74        68\n",
            "  Business/Finance       0.43      0.51      0.47        57\n",
            "    Policy/Economy       0.37      0.40      0.38        68\n",
            "            Sports       0.92      0.84      0.87        91\n",
            "              Food       0.44      0.45      0.44        69\n",
            "               AMA       0.77      0.76      0.77        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.57       712\n",
            "         macro avg       0.55      0.52      0.53       712\n",
            "      weighted avg       0.58      0.57      0.57       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Random Forest\n",
            "accuracy 0.5688202247191011\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.86      0.50      0.63        24\n",
            "     Non-Political       0.46      0.66      0.54        59\n",
            "     [R]eddiquette       0.50      0.40      0.44        68\n",
            "         Scheduled       0.57      0.31      0.40        52\n",
            "       Photography       0.76      0.62      0.68        21\n",
            "Science/Technology       0.50      0.57      0.53        68\n",
            "          Politics       0.55      0.76      0.64        68\n",
            "  Business/Finance       0.45      0.51      0.48        57\n",
            "    Policy/Economy       0.29      0.40      0.34        68\n",
            "            Sports       0.93      0.85      0.89        91\n",
            "              Food       0.61      0.45      0.52        69\n",
            "               AMA       0.86      0.68      0.76        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.57       712\n",
            "         macro avg       0.56      0.52      0.53       712\n",
            "      weighted avg       0.60      0.57      0.57       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of MLP Classifier\n",
            "accuracy 0.5\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.62      0.42      0.50        24\n",
            "     Non-Political       0.35      0.54      0.43        59\n",
            "     [R]eddiquette       0.43      0.35      0.39        68\n",
            "         Scheduled       0.31      0.31      0.31        52\n",
            "       Photography       0.65      0.52      0.58        21\n",
            "Science/Technology       0.37      0.44      0.40        68\n",
            "          Politics       0.81      0.74      0.77        68\n",
            "  Business/Finance       0.42      0.53      0.47        57\n",
            "    Policy/Economy       0.32      0.34      0.33        68\n",
            "            Sports       0.90      0.80      0.85        91\n",
            "              Food       0.48      0.33      0.39        69\n",
            "               AMA       0.64      0.51      0.57        63\n",
            "       Coronavirus       0.14      0.50      0.22         4\n",
            "\n",
            "          accuracy                           0.50       712\n",
            "         macro avg       0.50      0.49      0.48       712\n",
            "      weighted avg       0.53      0.50      0.51       712\n",
            "\n",
            "Trying with different Feature -----------------------\n",
            "Flair Detection using Body as Feature\n",
            "Results of Naive Bayes Classifier\n",
            "accuracy 0.2556179775280899\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        24\n",
            "     Non-Political       0.25      0.93      0.40        59\n",
            "     [R]eddiquette       0.43      0.04      0.08        68\n",
            "         Scheduled       0.00      0.00      0.00        52\n",
            "       Photography       0.00      0.00      0.00        21\n",
            "Science/Technology       0.00      0.00      0.00        68\n",
            "          Politics       0.15      0.91      0.25        68\n",
            "  Business/Finance       0.00      0.00      0.00        57\n",
            "    Policy/Economy       0.00      0.00      0.00        68\n",
            "            Sports       0.98      0.67      0.80        91\n",
            "              Food       1.00      0.01      0.03        69\n",
            "               AMA       0.00      0.00      0.00        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.26       712\n",
            "         macro avg       0.22      0.20      0.12       712\n",
            "      weighted avg       0.30      0.26      0.17       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Linear Support Vector Machine\n",
            "accuracy 0.2808988764044944\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.70      0.29      0.41        24\n",
            "     Non-Political       0.34      0.75      0.47        59\n",
            "     [R]eddiquette       0.50      0.22      0.31        68\n",
            "         Scheduled       1.00      0.02      0.04        52\n",
            "       Photography       0.75      0.14      0.24        21\n",
            "Science/Technology       0.00      0.00      0.00        68\n",
            "          Politics       0.64      0.10      0.18        68\n",
            "  Business/Finance       0.50      0.12      0.20        57\n",
            "    Policy/Economy       0.33      0.03      0.05        68\n",
            "            Sports       0.98      0.70      0.82        91\n",
            "              Food       0.10      0.59      0.17        69\n",
            "               AMA       0.75      0.14      0.24        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.28       712\n",
            "         macro avg       0.51      0.24      0.24       712\n",
            "      weighted avg       0.53      0.28      0.27       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Logistic Regression\n",
            "accuracy 0.2991573033707865\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.56      0.38      0.45        24\n",
            "     Non-Political       0.36      0.64      0.46        59\n",
            "     [R]eddiquette       0.41      0.22      0.29        68\n",
            "         Scheduled       1.00      0.04      0.07        52\n",
            "       Photography       0.25      0.14      0.18        21\n",
            "Science/Technology       0.13      0.03      0.05        68\n",
            "          Politics       0.15      0.96      0.26        68\n",
            "  Business/Finance       0.60      0.11      0.18        57\n",
            "    Policy/Economy       0.33      0.03      0.05        68\n",
            "            Sports       0.98      0.69      0.81        91\n",
            "              Food       0.40      0.03      0.05        69\n",
            "               AMA       0.86      0.10      0.17        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.30       712\n",
            "         macro avg       0.46      0.26      0.23       712\n",
            "      weighted avg       0.52      0.30      0.26       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Random Forest\n",
            "accuracy 0.2794943820224719\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.70      0.29      0.41        24\n",
            "     Non-Political       0.29      0.90      0.44        59\n",
            "     [R]eddiquette       0.80      0.12      0.21        68\n",
            "         Scheduled       1.00      0.02      0.04        52\n",
            "       Photography       0.33      0.05      0.08        21\n",
            "Science/Technology       0.00      0.00      0.00        68\n",
            "          Politics       0.15      0.91      0.25        68\n",
            "  Business/Finance       1.00      0.05      0.10        57\n",
            "    Policy/Economy       0.00      0.00      0.00        68\n",
            "            Sports       1.00      0.68      0.81        91\n",
            "              Food       0.00      0.00      0.00        69\n",
            "               AMA       0.40      0.03      0.06        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.28       712\n",
            "         macro avg       0.44      0.23      0.18       712\n",
            "      weighted avg       0.46      0.28      0.22       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of MLP Classifier\n",
            "accuracy 0.2696629213483146\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.40      0.08      0.14        24\n",
            "     Non-Political       0.39      0.44      0.42        59\n",
            "     [R]eddiquette       0.60      0.18      0.27        68\n",
            "         Scheduled       0.07      0.04      0.05        52\n",
            "       Photography       0.23      0.14      0.18        21\n",
            "Science/Technology       0.05      0.01      0.02        68\n",
            "          Politics       0.14      0.93      0.25        68\n",
            "  Business/Finance       0.21      0.12      0.16        57\n",
            "    Policy/Economy       0.50      0.01      0.03        68\n",
            "            Sports       0.97      0.68      0.80        91\n",
            "              Food       0.57      0.12      0.19        69\n",
            "               AMA       0.62      0.08      0.14        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.27       712\n",
            "         macro avg       0.37      0.22      0.20       712\n",
            "      weighted avg       0.43      0.27      0.25       712\n",
            "\n",
            "Trying with different Feature -----------------------\n",
            "Flair Detection using URL as Feature\n",
            "Results of Naive Bayes Classifier\n",
            "accuracy 0.37359550561797755\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        24\n",
            "     Non-Political       0.21      0.97      0.35        59\n",
            "     [R]eddiquette       0.66      0.31      0.42        68\n",
            "         Scheduled       1.00      0.02      0.04        52\n",
            "       Photography       0.00      0.00      0.00        21\n",
            "Science/Technology       0.27      0.04      0.08        68\n",
            "          Politics       0.38      0.74      0.50        68\n",
            "  Business/Finance       0.31      0.63      0.42        57\n",
            "    Policy/Economy       0.40      0.40      0.40        68\n",
            "            Sports       0.97      0.40      0.56        91\n",
            "              Food       0.65      0.16      0.26        69\n",
            "               AMA       0.80      0.38      0.52        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.37       712\n",
            "         macro avg       0.43      0.31      0.27       712\n",
            "      weighted avg       0.54      0.37      0.34       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Linear Support Vector Machine\n",
            "accuracy 0.40730337078651685\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        24\n",
            "     Non-Political       0.21      0.97      0.35        59\n",
            "     [R]eddiquette       0.61      0.29      0.40        68\n",
            "         Scheduled       0.48      0.23      0.31        52\n",
            "       Photography       0.88      0.33      0.48        21\n",
            "Science/Technology       0.19      0.09      0.12        68\n",
            "          Politics       0.44      0.74      0.55        68\n",
            "  Business/Finance       0.39      0.47      0.43        57\n",
            "    Policy/Economy       0.56      0.37      0.44        68\n",
            "            Sports       0.87      0.45      0.59        91\n",
            "              Food       0.50      0.23      0.32        69\n",
            "               AMA       0.69      0.46      0.55        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.41       712\n",
            "         macro avg       0.45      0.36      0.35       712\n",
            "      weighted avg       0.50      0.41      0.40       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Logistic Regression\n",
            "accuracy 0.4044943820224719\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        24\n",
            "     Non-Political       0.21      0.97      0.35        59\n",
            "     [R]eddiquette       0.58      0.31      0.40        68\n",
            "         Scheduled       0.52      0.25      0.34        52\n",
            "       Photography       0.80      0.19      0.31        21\n",
            "Science/Technology       0.12      0.06      0.08        68\n",
            "          Politics       0.43      0.78      0.55        68\n",
            "  Business/Finance       0.43      0.46      0.44        57\n",
            "    Policy/Economy       0.50      0.40      0.44        68\n",
            "            Sports       0.89      0.44      0.59        91\n",
            "              Food       0.57      0.23      0.33        69\n",
            "               AMA       0.79      0.43      0.56        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.40       712\n",
            "         macro avg       0.45      0.35      0.34       712\n",
            "      weighted avg       0.51      0.40      0.40       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Random Forest\n",
            "accuracy 0.3539325842696629\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        24\n",
            "     Non-Political       0.00      0.00      0.00        59\n",
            "     [R]eddiquette       0.74      0.29      0.42        68\n",
            "         Scheduled       0.42      0.10      0.16        52\n",
            "       Photography       0.80      0.19      0.31        21\n",
            "Science/Technology       0.20      0.06      0.09        68\n",
            "          Politics       0.36      0.76      0.49        68\n",
            "  Business/Finance       0.35      0.49      0.41        57\n",
            "    Policy/Economy       0.48      0.34      0.40        68\n",
            "            Sports       0.24      0.81      0.37        91\n",
            "              Food       0.36      0.23      0.28        69\n",
            "               AMA       0.96      0.41      0.58        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.35       712\n",
            "         macro avg       0.38      0.28      0.27       712\n",
            "      weighted avg       0.40      0.35      0.31       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of MLP Classifier\n",
            "accuracy 0.29775280898876405\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        24\n",
            "     Non-Political       0.21      0.97      0.35        59\n",
            "     [R]eddiquette       0.58      0.21      0.30        68\n",
            "         Scheduled       0.47      0.15      0.23        52\n",
            "       Photography       0.29      0.10      0.14        21\n",
            "Science/Technology       0.11      0.31      0.16        68\n",
            "          Politics       0.00      0.00      0.00        68\n",
            "  Business/Finance       0.34      0.39      0.36        57\n",
            "    Policy/Economy       0.57      0.19      0.29        68\n",
            "            Sports       0.95      0.41      0.57        91\n",
            "              Food       0.38      0.22      0.28        69\n",
            "               AMA       0.79      0.37      0.50        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.30       712\n",
            "         macro avg       0.36      0.25      0.24       712\n",
            "      weighted avg       0.44      0.30      0.29       712\n",
            "\n",
            "Trying with different Feature -----------------------\n",
            "Flair Detection using Comments as Feature\n",
            "Results of Naive Bayes Classifier\n",
            "accuracy 0.34831460674157305\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        24\n",
            "     Non-Political       0.16      0.66      0.25        59\n",
            "     [R]eddiquette       0.00      0.00      0.00        68\n",
            "         Scheduled       0.50      0.04      0.07        52\n",
            "       Photography       0.00      0.00      0.00        21\n",
            "Science/Technology       0.23      0.04      0.07        68\n",
            "          Politics       0.90      0.40      0.55        68\n",
            "  Business/Finance       0.44      0.49      0.46        57\n",
            "    Policy/Economy       0.30      0.87      0.45        68\n",
            "            Sports       0.66      0.67      0.66        91\n",
            "              Food       0.80      0.17      0.29        69\n",
            "               AMA       0.36      0.27      0.31        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.35       712\n",
            "         macro avg       0.33      0.28      0.24       712\n",
            "      weighted avg       0.41      0.35      0.31       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Linear Support Vector Machine\n",
            "accuracy 0.5224719101123596\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.67      0.58      0.62        24\n",
            "     Non-Political       0.28      0.36      0.32        59\n",
            "     [R]eddiquette       0.44      0.34      0.38        68\n",
            "         Scheduled       0.54      0.48      0.51        52\n",
            "       Photography       0.65      0.71      0.68        21\n",
            "Science/Technology       0.21      0.06      0.09        68\n",
            "          Politics       0.47      0.88      0.61        68\n",
            "  Business/Finance       0.58      0.58      0.58        57\n",
            "    Policy/Economy       0.52      0.63      0.57        68\n",
            "            Sports       0.65      0.80      0.72        91\n",
            "              Food       0.57      0.33      0.42        69\n",
            "               AMA       0.67      0.57      0.62        63\n",
            "       Coronavirus       1.00      0.50      0.67         4\n",
            "\n",
            "          accuracy                           0.52       712\n",
            "         macro avg       0.56      0.53      0.52       712\n",
            "      weighted avg       0.51      0.52      0.50       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Logistic Regression\n",
            "accuracy 0.5603932584269663\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.59      0.54      0.57        24\n",
            "     Non-Political       0.35      0.41      0.38        59\n",
            "     [R]eddiquette       0.51      0.38      0.44        68\n",
            "         Scheduled       0.58      0.56      0.57        52\n",
            "       Photography       0.56      0.71      0.63        21\n",
            "Science/Technology       0.31      0.24      0.27        68\n",
            "          Politics       0.63      0.85      0.72        68\n",
            "  Business/Finance       0.56      0.63      0.60        57\n",
            "    Policy/Economy       0.60      0.60      0.60        68\n",
            "            Sports       0.76      0.81      0.78        91\n",
            "              Food       0.55      0.35      0.42        69\n",
            "               AMA       0.55      0.63      0.59        63\n",
            "       Coronavirus       0.75      0.75      0.75         4\n",
            "\n",
            "          accuracy                           0.56       712\n",
            "         macro avg       0.56      0.57      0.56       712\n",
            "      weighted avg       0.55      0.56      0.55       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Random Forest\n",
            "accuracy 0.5112359550561798\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.82      0.58      0.68        24\n",
            "     Non-Political       0.30      0.41      0.35        59\n",
            "     [R]eddiquette       0.54      0.31      0.39        68\n",
            "         Scheduled       0.58      0.42      0.49        52\n",
            "       Photography       0.76      0.62      0.68        21\n",
            "Science/Technology       0.40      0.15      0.22        68\n",
            "          Politics       0.35      0.82      0.49        68\n",
            "  Business/Finance       0.51      0.49      0.50        57\n",
            "    Policy/Economy       0.51      0.66      0.57        68\n",
            "            Sports       0.88      0.81      0.85        91\n",
            "              Food       0.52      0.25      0.33        69\n",
            "               AMA       0.51      0.59      0.55        63\n",
            "       Coronavirus       1.00      0.75      0.86         4\n",
            "\n",
            "          accuracy                           0.51       712\n",
            "         macro avg       0.59      0.53      0.54       712\n",
            "      weighted avg       0.54      0.51      0.50       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of MLP Classifier\n",
            "accuracy 0.4705056179775281\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        24\n",
            "     Non-Political       0.24      0.31      0.27        59\n",
            "     [R]eddiquette       0.51      0.29      0.37        68\n",
            "         Scheduled       0.65      0.42      0.51        52\n",
            "       Photography       0.85      0.52      0.65        21\n",
            "Science/Technology       0.15      0.19      0.17        68\n",
            "          Politics       0.61      0.75      0.68        68\n",
            "  Business/Finance       0.47      0.51      0.49        57\n",
            "    Policy/Economy       0.60      0.50      0.54        68\n",
            "            Sports       0.62      0.77      0.69        91\n",
            "              Food       0.44      0.41      0.42        69\n",
            "               AMA       0.45      0.59      0.51        63\n",
            "       Coronavirus       1.00      0.50      0.67         4\n",
            "\n",
            "          accuracy                           0.47       712\n",
            "         macro avg       0.51      0.44      0.46       712\n",
            "      weighted avg       0.48      0.47      0.46       712\n",
            "\n",
            "Trying with different Feature -----------------------\n",
            "Flair Detection using Combined Features\n",
            "Results of Naive Bayes Classifier\n",
            "accuracy 0.40870786516853935\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        24\n",
            "     Non-Political       0.15      0.80      0.25        59\n",
            "     [R]eddiquette       0.59      0.19      0.29        68\n",
            "         Scheduled       0.67      0.04      0.07        52\n",
            "       Photography       0.00      0.00      0.00        21\n",
            "Science/Technology       0.41      0.10      0.16        68\n",
            "          Politics       0.92      0.50      0.65        68\n",
            "  Business/Finance       0.42      0.54      0.48        57\n",
            "    Policy/Economy       0.44      0.78      0.56        68\n",
            "            Sports       0.78      0.68      0.73        91\n",
            "              Food       0.83      0.28      0.41        69\n",
            "               AMA       0.92      0.37      0.52        63\n",
            "       Coronavirus       0.00      0.00      0.00         4\n",
            "\n",
            "          accuracy                           0.41       712\n",
            "         macro avg       0.47      0.33      0.32       712\n",
            "      weighted avg       0.58      0.41      0.40       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Linear Support Vector Machine\n",
            "accuracy 0.6502808988764045\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.76      0.54      0.63        24\n",
            "     Non-Political       0.36      0.47      0.41        59\n",
            "     [R]eddiquette       0.70      0.62      0.66        68\n",
            "         Scheduled       0.63      0.52      0.57        52\n",
            "       Photography       0.74      0.67      0.70        21\n",
            "Science/Technology       0.59      0.15      0.24        68\n",
            "          Politics       0.65      0.94      0.77        68\n",
            "  Business/Finance       0.65      0.65      0.65        57\n",
            "    Policy/Economy       0.59      0.65      0.62        68\n",
            "            Sports       0.81      0.91      0.86        91\n",
            "              Food       0.62      0.58      0.60        69\n",
            "               AMA       0.76      0.94      0.84        63\n",
            "       Coronavirus       1.00      0.50      0.67         4\n",
            "\n",
            "          accuracy                           0.65       712\n",
            "         macro avg       0.68      0.63      0.63       712\n",
            "      weighted avg       0.65      0.65      0.63       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Logistic Regression\n",
            "accuracy 0.6797752808988764\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.67      0.50      0.57        24\n",
            "     Non-Political       0.44      0.58      0.50        59\n",
            "     [R]eddiquette       0.78      0.62      0.69        68\n",
            "         Scheduled       0.56      0.63      0.59        52\n",
            "       Photography       0.93      0.62      0.74        21\n",
            "Science/Technology       0.41      0.32      0.36        68\n",
            "          Politics       0.81      0.91      0.86        68\n",
            "  Business/Finance       0.60      0.70      0.65        57\n",
            "    Policy/Economy       0.60      0.60      0.60        68\n",
            "            Sports       0.92      0.91      0.92        91\n",
            "              Food       0.67      0.62      0.65        69\n",
            "               AMA       0.85      0.90      0.88        63\n",
            "       Coronavirus       1.00      0.50      0.67         4\n",
            "\n",
            "          accuracy                           0.68       712\n",
            "         macro avg       0.71      0.65      0.67       712\n",
            "      weighted avg       0.69      0.68      0.68       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of Random Forest\n",
            "accuracy 0.6558988764044944\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.81      0.54      0.65        24\n",
            "     Non-Political       0.39      0.73      0.51        59\n",
            "     [R]eddiquette       0.81      0.51      0.63        68\n",
            "         Scheduled       0.65      0.46      0.54        52\n",
            "       Photography       0.81      0.62      0.70        21\n",
            "Science/Technology       0.43      0.18      0.25        68\n",
            "          Politics       0.62      0.94      0.74        68\n",
            "  Business/Finance       0.71      0.65      0.68        57\n",
            "    Policy/Economy       0.57      0.69      0.62        68\n",
            "            Sports       0.98      0.88      0.92        91\n",
            "              Food       0.62      0.70      0.65        69\n",
            "               AMA       0.80      0.76      0.78        63\n",
            "       Coronavirus       1.00      0.75      0.86         4\n",
            "\n",
            "          accuracy                           0.66       712\n",
            "         macro avg       0.71      0.65      0.66       712\n",
            "      weighted avg       0.68      0.66      0.65       712\n",
            "\n",
            "----------------------------------------------------------------------------------\n",
            "Results of MLP Classifier\n",
            "accuracy 0.5196629213483146\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.57      0.33      0.42        24\n",
            "     Non-Political       0.21      0.54      0.30        59\n",
            "     [R]eddiquette       0.58      0.49      0.53        68\n",
            "         Scheduled       0.43      0.44      0.44        52\n",
            "       Photography       0.36      0.38      0.37        21\n",
            "Science/Technology       0.24      0.12      0.16        68\n",
            "          Politics       0.61      0.81      0.70        68\n",
            "  Business/Finance       0.47      0.70      0.56        57\n",
            "    Policy/Economy       0.67      0.51      0.58        68\n",
            "            Sports       0.94      0.69      0.80        91\n",
            "              Food       0.67      0.41      0.50        69\n",
            "               AMA       0.88      0.57      0.69        63\n",
            "       Coronavirus       0.25      0.25      0.25         4\n",
            "\n",
            "          accuracy                           0.52       712\n",
            "         macro avg       0.53      0.48      0.49       712\n",
            "      weighted avg       0.58      0.52      0.53       712\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYVq76-dkS9x",
        "colab_type": "text"
      },
      "source": [
        "**Clearly combined features is a better choice as per the classification report of different alorithms**\n",
        "\n",
        "Saving the logistic regression model for deploying on website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdiPEGiuuyd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#choosing logistic regression trained on combine features as final model\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, flair, test_size=0.2, random_state = 42)\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg = logreg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "pickle.dump(logreg,open(\"model_final(reddit).pkl\",'wb'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf9B2jH5lbab",
        "colab_type": "text"
      },
      "source": [
        "**Testing the saved model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml-Z3c4DmPpr",
        "colab_type": "text"
      },
      "source": [
        "Installing and importing all the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRoWfZuYBZ5u",
        "colab_type": "code",
        "outputId": "b763fdbb-bdb2-43ed-ac72-664b5800b835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "\n",
        "!pip install praw\n",
        "import praw\n",
        "from praw.models import MoreComments\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Requirement already satisfied: prawcore<2.0,>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from praw) (1.3.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.6/dist-packages (from praw) (0.57.0)\n",
            "Requirement already satisfied: update-checker>=0.16 in /usr/local/lib/python3.6/dist-packages (from praw) (0.16)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from prawcore<2.0,>=1.3.0->praw) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.54.0->praw) (1.12.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQMNT0N0mVTo",
        "colab_type": "text"
      },
      "source": [
        "Authentication part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfQ-k69bBiGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reddit = praw.Reddit(client_id = \"####\",\n",
        "                     client_secret = \"####\",\n",
        "                     user_agent = \"####\",\n",
        "                     username = \"####\",\n",
        "                     password = \"####\")\n",
        "\n",
        "subreddit = reddit.subreddit('india')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJLrbkuImYSN",
        "colab_type": "text"
      },
      "source": [
        "Downloading nltk corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh39tmNXCG-g",
        "colab_type": "code",
        "outputId": "664bd8c5-5ebe-46b8-d90c-175828686695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHcK0Velmb4J",
        "colab_type": "text"
      },
      "source": [
        "**Defining the clean text function to apply cleaning on the data scrapped from the test url before passing it in the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX0P95mtCCBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replace_by_space = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "replace_symbol = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = replace_by_space.sub(' ', text) # replace certain symbols by space in text\n",
        "    text = replace_symbol.sub('', text) # delete symbols from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove STOPWORDS from text\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tYp_5F4m6u5",
        "colab_type": "text"
      },
      "source": [
        "**loading the saved model**\n",
        "\n",
        "**Given the url , this functions scrape data from that url which includes title,body,url,top 15 comments and then calls the saved model for prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUd8isAvu94g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing\n",
        "\n",
        "\n",
        "with open('/content/model_final(reddit).pkl', 'rb') as f:\n",
        "    loaded_model = pickle.load(f)\n",
        "\n",
        "\n",
        "def detect_flair(url):\n",
        "\n",
        "  submission = reddit.submission(url=url)\n",
        "\n",
        "  data = {}\n",
        "\n",
        "  data['title'] = submission.title\n",
        "  data['url'] = submission.url\n",
        "  data['body'] = submission.body\n",
        "\n",
        "  submission.comments.replace_more(limit=None)\n",
        "  comment = ''\n",
        "  chk=0\n",
        "  for top_level_comment in submission.comments:\n",
        "    comment = comment + ' ' + top_level_comment.body\n",
        "    chk=chk+1\n",
        "    if(chk>15):\n",
        "      break\n",
        "  data[\"comment\"] = comment\n",
        "  data['title'] = clean_text(data['title'])\n",
        "  data['comment'] = clean_text(data['comment'])\n",
        "  data['body'] = clean_text(data['body'])\n",
        "  data['url'] = clean_text(data['url'])\n",
        "\n",
        "  data['combine'] = data['title'] + data['comment'] + data['url']+data['body']\n",
        "  \n",
        "  return loaded_model.predict([data['combine']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o-NvShDnoSY",
        "colab_type": "text"
      },
      "source": [
        "**Sample prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAGURxZGvBuS",
        "colab_type": "code",
        "outputId": "332f291a-5b59-4bba-9d91-a532990c9664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "detect_flair(\"https://www.reddit.com/r/india/comments/g88vql/govt_discomfort_with_rel_jio_tower_deal_over_fdi/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Business/Finance'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1JU607kBVbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}